{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a69226b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Amazon Sale Report.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j9/yn87msd915g4hf9b0x0438rw0000gn/T/ipykernel_41574/2617468863.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mamazon_sales\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'Amazon Sale Report.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msales\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamazon_sales\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Amazon Sale Report.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Update the path to include the data directory\n",
    "amazon_sales = 'data/Amazon Sale Report.csv'\n",
    "\n",
    "# Now read the CSV file from the data directory\n",
    "sales = pd.read_csv(amazon_sales)\n",
    "\n",
    "amazon_sales= 'Amazon Sale Report.csv' \n",
    "\n",
    "sales=pd.read_csv(amazon_sales)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#CLEANING: \n",
    "\n",
    "sales = sales.drop(columns=['fulfilled-by', 'Unnamed: 22'])\n",
    "\n",
    "\n",
    "# Function to display initial data overview\n",
    "def data_overview(df, name):\n",
    "    print(f\"\\nOverview of {name} dataset:\")\n",
    "    print(df.info())\n",
    "    print(df.head())\n",
    "    print(f\"\\nNumber of duplicates in {name}: {df.duplicated().sum()}\")\n",
    "    print(f\"Missing values in {name}:\\n{df.isnull().sum()}\\n\")\n",
    "    \n",
    "# Replace missing values in 'Courier Status' with 'Unknown' since 5.33% are null\n",
    "sales['Courier Status'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Replace missing values in 'currency' with 'INR' since 6.04% are null & all non-null are INR\n",
    "sales['currency'].fillna('INR', inplace=True)\n",
    "\n",
    "# Calculate the mean and median of the 'Amount' column \n",
    "amount_mean = sales['Amount'].mean()\n",
    "amount_median = sales['Amount'].median()\n",
    "# Replace missing values in 'Amount' with the mean since 6.04% are null\n",
    "sales['Amount'].fillna(amount_mean, inplace=True)\n",
    "\n",
    "# Replace missing values with 'Unknown'\n",
    "columns_to_fill = ['ship-city', 'ship-state', 'ship-postal-code', 'ship-country']\n",
    "\n",
    "for column in columns_to_fill:\n",
    "    sales[column].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Replace NaN values in 'promotion-ids' with 'None'\n",
    "sales['promotion-ids'] = sales['promotion-ids'].fillna('None')\n",
    "\n",
    "\n",
    "sales['Date'] = pd.to_datetime(sales['Date'], errors='coerce')\n",
    "sales['Fulfilment'] = sales['Fulfilment'].astype('category')\n",
    "sales.columns = sales.columns.str.strip()\n",
    "\n",
    "# List of columns to convert to 'category' type\n",
    "columns_to_convert = ['Fulfilment', 'Sales Channel', 'ship-service-level']\n",
    "\n",
    "# Convert the columns to 'category' type\n",
    "sales[columns_to_convert] = sales[columns_to_convert].astype('category')\n",
    "     \n",
    "    \n",
    "# Display initial data overviews\n",
    "data_overview(sales, \"sales\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d99d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution Of 'Amount' In Sales\n",
    "\n",
    "# Plot histogram of 'Amount'\n",
    "plt.hist(sales['Amount'], bins=50, color='blue', alpha=0.5, label='All Data')\n",
    "\n",
    "\n",
    "#Find outliers of 'Amount'\n",
    "from scipy.stats import zscore\n",
    "\n",
    "sales['z_score'] = zscore(sales['Amount'])\n",
    "outliers = sales[sales['z_score'].abs() > 3]\n",
    "\n",
    "# Plot histogram of outliers against all data\n",
    "plt.hist(outliers['Amount'], bins=50, color='red', alpha=0.7, label='Outliers')\n",
    "\n",
    "plt.xlabel('Amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Comparison of Distribution: All Data vs Outliers')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plot distribution with outliers\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(sales['Amount'], kde=True, bins=50)\n",
    "plt.title('Distribution of Amount with Outliers')\n",
    "plt.xlabel('Amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Outliers are those greater than 2000\n",
    "filtered_sales = sales[sales['Amount'] <= 2000]\n",
    "\n",
    "\n",
    "# Plot distribution without outliers\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(filtered_sales['Amount'], kde=True, bins=50)\n",
    "plt.title('Distribution of Amount without Outliers')\n",
    "plt.xlabel('Amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4334409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Sales Per Month\n",
    "\n",
    "\n",
    "daily_sales =filtered_sales.groupby('Date')['Amount'].sum().reset_index()\n",
    "\n",
    "\n",
    "# Get the min and max values for scaling\n",
    "min_y_all = daily_sales['Amount'].min()\n",
    "max_y_all = daily_sales['Amount'].max()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(daily_sales.index, daily_sales['Amount'], marker='o')\n",
    "plt.title('Filltered Total Sales Per Day')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.ylim(0,  max_y_all+20000)  # Set y-axis limits\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Filter out sales data for March\n",
    "sales_filtered = sales[~sales['Date'].dt.month.isin([3])]\n",
    "\n",
    "# Group by month and sum the sales\n",
    "monthly_sales_filtered = sales_filtered.groupby(sales_filtered['Date'].dt.to_period('M'))['Amount'].sum()\n",
    "\n",
    "# Plot monthly sales excluding March since only one day in March data\n",
    "plt.figure(figsize=(12, 6))\n",
    "monthly_sales_filtered.plot(kind='bar')\n",
    "plt.title('Filtered Total Sales Per Month (Excluding March)')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01951f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#SKU Exploration\n",
    "\n",
    "\n",
    "#Top 20 SKUs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the counts of each SKU\n",
    "sku_counts = sales['SKU'].value_counts()\n",
    "\n",
    "print(sales['SKU'].nunique())\n",
    "print(sales['SKU'].describe())\n",
    "\n",
    "# Filter for the top 20 SKUs if necessary\n",
    "top_20_skus = sku_counts.head(20).reset_index()\n",
    "top_20_skus.columns = ['SKU', 'Count']\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='SKU', y='Count', data=top_20_skus, palette='viridis')\n",
    "plt.title('Distribution of Top 20 SKUs')\n",
    "plt.xlabel('SKU')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)  # Rotate SKU labels for better readability\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#Simplifying SKUs By Eliminating Sizes\n",
    "\n",
    "# Define a list of size suffixes to remove\n",
    "size_suffixes = ['-XS','-S', '-M', '-L', '-XL', '-XXL','-XXXL']\n",
    "\n",
    "# Remove size suffixes from the SKU column\n",
    "def remove_size_suffix(sku):\n",
    "    for suffix in size_suffixes:\n",
    "        if sku.endswith(suffix):\n",
    "            return sku[:-len(suffix)]\n",
    "    return sku\n",
    "\n",
    "sales['Simplified_SKU'] = sales['SKU'].apply(remove_size_suffix)\n",
    "\n",
    "# Get the counts of each simplified SKU\n",
    "simplified_sku_counts = sales['Simplified_SKU'].value_counts()\n",
    "\n",
    "# Output the number of unique simplified SKUs\n",
    "#print(\"Unique simplified SKU count:\", len(simplified_sku_counts))\n",
    "\n",
    "# Describe the distribution of simplified SKUs\n",
    "#print(simplified_sku_counts.describe())\n",
    "\n",
    "# Optionally, if you want to see the top simplified SKUs\n",
    "top_simplified_skus = simplified_sku_counts.head(20).reset_index()\n",
    "top_simplified_skus.columns = ['SKU', 'Count']\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of the simplified SKUs\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.barplot(x='SKU', y='Count', data=top_simplified_skus, palette='viridis')\n",
    "plt.title('Distribution of Top 20 Simplified SKUs')\n",
    "plt.xlabel('SKU')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)  # Rotate SKU labels for better readability\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(top_simplified_skus)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d1c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEGMENTATION BEGIN\n",
    "\n",
    "# Define broader categories\n",
    "category_mapping = {\n",
    "    'Set': 'Accessories',\n",
    "    'kurta': 'Ethnic Wear',\n",
    "    'Western Dress': 'Western Wear',\n",
    "    'Top': 'Western Wear',\n",
    "    'Ethnic Dress': 'Ethnic Wear',\n",
    "    'Bottom': 'Accessories',\n",
    "    'Saree': 'Ethnic Wear',\n",
    "    'Blouse': 'Accessories',\n",
    "    'Dupatta': 'Ethnic Wear'\n",
    "}\n",
    "\n",
    "# Apply the mapping to create a new column for broader segments\n",
    "sales['Segment'] = sales['Category'].map(category_mapping)\n",
    "\n",
    "# Calculate total sales by segment\n",
    "segment_sales = sales.groupby('Segment')['Amount'].sum()\n",
    "\n",
    "# Plot the sales by segment\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=segment_sales.index, y=segment_sales.values)\n",
    "plt.title('Total Sales by Segment')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.xlabel('Segment')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7aa7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample DataFrame for demonstration\n",
    "# Replace this with your actual DataFrame\n",
    "# sales = pd.DataFrame({'SKU': [...], 'Category': [...], 'Amount': [...]})\n",
    "\n",
    "# Define a list of size suffixes to remove\n",
    "size_suffixes = ['-XS','-S', '-M', '-L', '-XL', '-XXL','-XXXL']\n",
    "\n",
    "# Function to remove size suffixes from SKUs\n",
    "def remove_size_suffix(sku):\n",
    "    for suffix in size_suffixes:\n",
    "        if sku.endswith(suffix):\n",
    "            return sku[:-len(suffix)]\n",
    "    return sku\n",
    "\n",
    "# Apply the function to create the 'Simplified_SKU' column\n",
    "sales['Simplified_SKU'] = sales['SKU'].apply(remove_size_suffix)\n",
    "\n",
    "# Group by 'Simplified_SKU' and calculate the total amount\n",
    "sku_amounts = sales.groupby(['Simplified_SKU', 'Category'])['Amount'].sum().reset_index(name='Total_Amount')\n",
    "\n",
    "# Get the top 20 SKUs by total amount\n",
    "top_20_skus = sku_amounts.nlargest(20, 'Total_Amount')\n",
    "\n",
    "# Create a color palette for the categories\n",
    "palette = sns.color_palette(\"husl\", len(top_20_skus['Category'].unique()))\n",
    "\n",
    "# Plot the top 20 SKUs by total amount with colors representing categories\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.barplot(x='Total_Amount', y='Simplified_SKU', hue='Category', data=top_20_skus, palette=palette)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Top 20 Simplified SKUs by Total Amount (Categorized)')\n",
    "plt.xlabel('Total Amount')\n",
    "plt.ylabel('Simplified SKU')\n",
    "plt.legend(title='Category', loc='right')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd32929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
